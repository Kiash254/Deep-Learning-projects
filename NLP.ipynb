{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CNpg1dWirEPa"
      },
      "outputs": [],
      "source": [
        "!pip install nltk -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AFMPosZXscXN"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import pos_tag, ne_chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3LzMjsUsswu",
        "outputId": "1122b0d7-1191-4e33-d5e5-dd33e951f4e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources to get the dataset\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i6FuKubGsy1C"
      },
      "outputs": [],
      "source": [
        "# Sample text for demonstration\n",
        "text = \"The quick brown foxes jumped over the lazy dogs. John works at Apple Inc. in California.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DOymWWkFs6Er"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "words = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OeQoNwOVs_hE"
      },
      "outputs": [],
      "source": [
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2orH224tCoR",
        "outputId": "98e391f2-d297-4018-ebcf-c6a5f904cacc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "# Download the 'wordnet' resource\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EIujz3S7tIqf"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EYJVTNfKtvRm"
      },
      "outputs": [],
      "source": [
        "# Named Entity Recognition (NER)\n",
        "def named_entity_recognition(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged_words = pos_tag(words)\n",
        "    named_entities = ne_chunk(tagged_words)\n",
        "    return named_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZKbR5ct1AS",
        "outputId": "6eef2d3b-318f-44bd-f793-93c3aea8035e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text:  The quick brown foxes jumped over the lazy dogs. John works at Apple Inc. in California.\n",
            "Tokenized Text:  ['The', 'quick', 'brown', 'foxes', 'jumped', 'over', 'the', 'lazy', 'dogs', '.', 'John', 'works', 'at', 'Apple', 'Inc.', 'in', 'California', '.']\n",
            "Stemmed Text:  ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog', '.', 'john', 'work', 'at', 'appl', 'inc.', 'in', 'california', '.']\n",
            "Lemmatized Text:  <WordNetLemmatizer>\n",
            "Normalized Text:  ['quick', 'brown', 'foxes', 'jumped', 'lazy', 'dogs', 'john', 'works', 'apple', 'california']\n",
            "Named Entity Recognition:\n",
            "(S\n",
            "  The/DT\n",
            "  quick/JJ\n",
            "  brown/NN\n",
            "  foxes/NNS\n",
            "  jumped/VBD\n",
            "  over/IN\n",
            "  the/DT\n",
            "  lazy/JJ\n",
            "  dogs/NNS\n",
            "  ./.\n",
            "  (PERSON John/NNP)\n",
            "  works/VBZ\n",
            "  at/IN\n",
            "  (ORGANIZATION Apple/NNP Inc./NNP)\n",
            "  in/IN\n",
            "  (GPE California/NNP)\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "# Display the results\n",
        "print(\"Original Text: \", text)\n",
        "print(\"Tokenized Text: \", words)\n",
        "print(\"Stemmed Text: \", stemmed_words)\n",
        "print(\"Lemmatized Text: \", lemmatizer)\n",
        "print(\"Normalized Text: \", filtered_words)\n",
        "print(\"Named Entity Recognition:\")\n",
        "print(named_entity_recognition(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qobrh5Ust4Hi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
